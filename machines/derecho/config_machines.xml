  <machine MACH="derecho">
    <DESC>NCAR AMD EPYC system</DESC>
    <OS>CNL</OS>
    <COMPILERS>intel,gnu,nvhpc,intel-oneapi,intel-classic</COMPILERS>
    <MPILIBS>mpich</MPILIBS>
    <CIME_OUTPUT_ROOT>$ENV{SCRATCH}</CIME_OUTPUT_ROOT>
    <DIN_LOC_ROOT>$ENV{CESMDATAROOT}/inputdata</DIN_LOC_ROOT>
    <DIN_LOC_ROOT_CLMFORC>$ENV{CESMDATAROOT}/inputdata/atm/datm7</DIN_LOC_ROOT_CLMFORC>
    <DOUT_S_ROOT>$CIME_OUTPUT_ROOT/archive/$CASE</DOUT_S_ROOT>
    <BASELINE_ROOT>$ENV{CESMDATAROOT}/cesm_baselines</BASELINE_ROOT>
    <CCSM_CPRNC>$ENV{CESMDATAROOT}/cprnc/cprnc</CCSM_CPRNC>
    <GMAKE_J>16</GMAKE_J>
    <BATCH_SYSTEM>pbs</BATCH_SYSTEM>
    <SUPPORTED_BY>cseg</SUPPORTED_BY>
    <MAX_TASKS_PER_NODE>128</MAX_TASKS_PER_NODE>
    <MAX_GPUS_PER_NODE>4</MAX_GPUS_PER_NODE>
    <MAX_MPITASKS_PER_NODE>128</MAX_MPITASKS_PER_NODE>
    <MAX_CPUTASKS_PER_GPU_NODE>64</MAX_CPUTASKS_PER_GPU_NODE>
    <GPU_TYPE>none,a100</GPU_TYPE>
    <GPU_OFFLOAD>none,openacc,openmp,combined</GPU_OFFLOAD>
    <MPI_GPU_WRAPPER_SCRIPT>set_gpu_rank</MPI_GPU_WRAPPER_SCRIPT>
    <PROJECT_REQUIRED>TRUE</PROJECT_REQUIRED>
    <mpirun mpilib="default">
      <executable>mpibind</executable>
      <arguments>
        <arg name="label"> --label</arg>
	<arg name="buffer"> --line-buffer</arg>
	<arg name="separator"> -- </arg>
      </arguments>
   </mpirun>
    <module_system type="module" allow_error="true">
      <init_path lang="perl">$ENV{LMOD_ROOT}/lmod/init/perl</init_path>
      <init_path lang="python">$ENV{LMOD_ROOT}/lmod/init/env_modules_python.py</init_path>
      <init_path lang="sh">$ENV{LMOD_ROOT}/lmod/init/sh</init_path>
      <init_path lang="csh">$ENV{LMOD_ROOT}/lmod/init/csh</init_path>
      <cmd_path lang="perl">$ENV{LMOD_ROOT}/lmod/libexec/lmod perl</cmd_path>
      <cmd_path lang="python">$ENV{LMOD_ROOT}/lmod/libexec/lmod python</cmd_path>
      <cmd_path lang="sh">module</cmd_path>
      <cmd_path lang="csh">module</cmd_path>
      <modules>
	<command name="load">cesmdev/1.0</command>
	<command name="load">ncarenv/23.09</command>
        <command name="purge"/>
	<command name="load">craype</command>
      </modules>
      <modules compiler="intel">
        <command name="load">intel/2023.2.1</command>
	<command name="load">mkl</command>
      </modules>
      <modules compiler="intel-oneapi">
        <command name="load">intel-oneapi/2023.2.1</command>
	<command name="load">mkl</command>
      </modules>
      <modules compiler="intel-classic">
        <command name="load">intel-classic/2023.2.1</command>
	<command name="load">mkl</command>
      </modules>
      <modules compiler="cray">
        <command name="load">cce/15.0.1</command>
        <command name="load">cray-libsci/23.02.1.1</command>
      </modules>
      <modules compiler="gnu">
        <command name="load">gcc/12.2.0</command>
        <command name="load">cray-libsci/23.02.1.1</command>
      </modules>
      <modules compiler="nvhpc">
        <command name="load">nvhpc/24.3</command>
      </modules>

      <modules>
	<command name="load">ncarcompilers/1.0.0</command>
        <command name="load">cmake</command>
      </modules>
      <modules mpilib="mpich">
	<command name="load">cray-mpich/8.1.27</command>
      </modules>

      <modules mpilib="mpich" compiler="nvhpc" gpu_offload="!none">
        <command name="load">cuda/12.2.1</command>
      </modules>

      <modules mpilib="mpi-serial">
        <command name="load">mpi-serial/2.3.0</command>
        <command name="load">netcdf/4.9.2</command>
      </modules>

      <modules mpilib="!mpi-serial">
        <command name="load">netcdf-mpi/4.9.2</command>
        <command name="load">parallel-netcdf/1.12.3</command>
      </modules>

      <modules DEBUG="FALSE">
	<command name="load">parallelio/2.6.2</command>
	<command name="load">esmf/8.6.0</command>
      </modules>

      <modules DEBUG="TRUE" mpilib="mpi-serial">
	<command name="load">parallelio/2.6.2</command>
	<command name="load">esmf/8.6.0</command>
      </modules>

      <modules DEBUG="TRUE" mpilib="!mpi-serial">
	<command name="load">parallelio/2.6.2-debug</command>
	<command name="load">esmf/8.6.0-debug</command>
      </modules>
    </module_system>

    <environment_variables>
      <env name="OMP_STACKSIZE">64M</env>
      <env name="FI_CXI_RX_MATCH_MODE">hybrid</env>
      <!-- https://support.hpe.com/hpesc/public/docDisplay?docId=a00129146en_us&docLocale=en_US -->
      <env name="FI_MR_CACHE_MONITOR">memhooks</env>
    </environment_variables>
    <!-- derecho has both gpfs and lustre file systems so I think this setting may cause issues -->
    <!--    <environment_variables mpilib="mpich">
         <env name="MPICH_MPIIO_HINTS">*:romio_cb_read=enable:romio_cb_write=enable:striping_factor=2</env>
         </environment_variables>
      -->
    <environment_variables comp_interface="nuopc">
      <!-- required on all systems for timing file output --> 
      <env name="ESMF_RUNTIME_PROFILE">ON</env>
      <env name="ESMF_RUNTIME_PROFILE_OUTPUT">SUMMARY</env>
    </environment_variables>
    <environment_variables compiler="nvhpc" gpu_offload="!none">
      <env name="NCAR_LIBS_CUDA">-lcuda -lcudart</env>
    </environment_variables>
  </machine>
